{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "new_dir ='half_cleaned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_lines(lines):\n",
    "    filtered_lines = []\n",
    "\n",
    "    para = []\n",
    "    for i, line in enumerate(lines):\n",
    "\n",
    "        line = line.strip('\\x0c')#.strip('p.')\n",
    "        words = line.split(' ')\n",
    "        words = [word for word in words if word != '']\n",
    "#         if i == 2586:\n",
    "#             print(words)\n",
    "\n",
    "#         if len(words) <= 5 and  words[0] != '\\n' and '.' not in words and '.' not in words and '.' not in words:\n",
    "#             continue\n",
    "\n",
    "\n",
    "#         if len(words) <= 3 and  len(words) > 1 and words[0] != '\\n':\n",
    "#             continue\n",
    "\n",
    "        if len(words) > 0:\n",
    "            \n",
    "            if len(words) >= 1 and words[0].lower() == 'believe' and words[1].lower() == \"you\":\n",
    "                continue\n",
    "                \n",
    "            if words[0] == '/':\n",
    "                continue\n",
    "\n",
    "            if words[0][:4].lower() == 'page':\n",
    "                continue\n",
    "\n",
    "            if words[0].lower() in [\"exercise\", 'stage', 'part', 'chapter', 'aph', 'step', 'section']:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "#             if sum(['_' in word for word in words]) > 0:\n",
    "#                 continue\n",
    "\n",
    "            if len(words[0]) > 1 and words[0][0] == 'c' and words[0][1].isdigit():\n",
    "                continue\n",
    "\n",
    "                \n",
    "            if 'â€”' in words[0]:\n",
    "                continue\n",
    "\n",
    "            if '*' in words[0]:\n",
    "                continue\n",
    "\n",
    "\n",
    "            if ':' in words[0]:\n",
    "                continue\n",
    "\n",
    "            if '-' in words[0]:\n",
    "                continue\n",
    "                \n",
    "            if sum([c.isdigit() for c in words[-1]]) > 2:\n",
    "                continue\n",
    "                \n",
    "            \n",
    "                \n",
    "#             if 'chap' in words[0]:\n",
    "#                 continue\n",
    "                \n",
    "#             if '$' in words[0]:\n",
    "#                 continue\n",
    "\n",
    "    ##         if '/' in words[0]:\n",
    "    #             continue\n",
    "\n",
    "            if sum([len(word) == 1 for word in words]) > 8:\n",
    "                continue\n",
    "\n",
    "    #         if sum(['cid' in word for word in words]) > 0:\n",
    "    #             continue\n",
    "\n",
    "            # remove quotation\n",
    "    #         if words[0] != '\\n' and len(words) <=4 and sum(['\"' in word for word in words]) == 0:\n",
    "    #             continue\n",
    "\n",
    "    #         if words[0] != '\\n' and len(words) <=4 and sum(['\"' in word for word in words]) == 0:\n",
    "    #             continue\n",
    "            new_words = []\n",
    "            for word in words:\n",
    "                if 'cid' in word or 'tip' in word.lower() or '#' in word or 'element' in word.lower():\n",
    "                    #print('here')\n",
    "                    continue\n",
    "                new_words.append(word)\n",
    "\n",
    "            if len(new_words) > 0  and new_words[0][:1].isdigit():\n",
    "                words = new_words[1:]\n",
    "                new_line = ' '.join([word for word in words])\n",
    "                filtered_lines.append(new_line)\n",
    "        \n",
    "#             elif len(new_words) > 0  and new_words[0] == 's':\n",
    "#                 words = new_words[1:]\n",
    "#                 new_line = ' '.join([word for word in words])\n",
    "#                 filtered_lines.append(new_line)\n",
    "        \n",
    "        \n",
    "            else:\n",
    "                new_line = ' '.join([word for word in new_words])\n",
    "                filtered_lines.append(new_line)\n",
    "\n",
    "            \n",
    "    return filtered_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(old_dir, name):\n",
    "    with open(os.path.join(old_dir, name), 'r',  encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        filtered_lines = cleanup_lines(lines)\n",
    "\n",
    "    with open(os.path.join(new_dir, name), 'w',  encoding=\"utf-8\") as f:\n",
    "        for line in filtered_lines:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dir = 'Personal Development'\n",
    "name = 'Magic of Thinking Big - David Schwartz.txt'\n",
    "\n",
    "convert(old_dir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_lines(lines):\n",
    "\n",
    "    filtered_lines = []\n",
    "\n",
    "    para = []\n",
    "    for i, line in enumerate(lines):\n",
    "        #print(i)\n",
    "        line = line.strip('\\x0c')#.strip('p.')\n",
    "        words = line.split(' ')\n",
    "            \n",
    "        if line == '\\n':\n",
    "            \n",
    "            # combine lines\n",
    "            para = \" \".join(p.rstrip() for p in para)\n",
    "            filtered_lines.append(para)\n",
    "            para = []\n",
    "\n",
    "        else:\n",
    "\n",
    "            para.append(line)\n",
    "            \n",
    "    return filtered_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 half_cleaned/the little book of talent -52 tips for improving your skills.txt\n",
      "\n",
      "1 half_cleaned/(Psychology, Self-Help) Feeling Good - 100 Ways To Feel Better Every Day.txt\n",
      "\n",
      "2 half_cleaned/The Miracle Morning_ The Not-So - Hal Elrod.txt\n",
      "\n",
      "3 half_cleaned/101 Really Important Things You Already Know, But Keep Forgetting-Mantesh.txt\n",
      "\n",
      "4 half_cleaned/Breaking_the_Chain.txt\n",
      "\n",
      "5 half_cleaned/A New Earth.txt\n",
      "\n",
      "6 half_cleaned/Carnagie.txt\n",
      "\n",
      "7 half_cleaned/Daniel Kahneman - Thinking, Fast and Slow.txt\n",
      "\n",
      "8 half_cleaned/Motivate to Win How to Motivate Yourself and Others.txt\n",
      "\n",
      "9 half_cleaned/100 Ways to Motivate Yourself Change Your Life Forever.txt\n",
      "\n",
      "10 half_cleaned/The Happiness Trap - Russ Harris.txt\n",
      "\n",
      "11 half_cleaned/Antony Robbins - Awaken The Giant Within.txt\n",
      "\n",
      "12 half_cleaned/The Four Agreements A Practical Guide to Personal Freedom.txt\n",
      "\n",
      "13 half_cleaned/The_100__Brain_Course_-_Melvin_D._Saunders_0.txt\n",
      "\n",
      "14 half_cleaned/PowerOfWill.txt\n",
      "\n",
      "15 half_cleaned/Gratitude is the Only Attitude Being Thankful Will Take You the Distance.txt\n",
      "\n",
      "16 half_cleaned/LifeSecrets.txt\n",
      "\n",
      "17 half_cleaned/TheSecretofSuccess.txt\n",
      "\n",
      "18 half_cleaned/The 7 Habits of Highly Effective People by Stephen R. Covery-sAyYiEd.txt\n",
      "\n",
      "19 half_cleaned/365 Best Inspirational Quotes.txt\n",
      "\n",
      "20 half_cleaned/You Are Your Choices 50 Ways to Live the Good Life.txt\n",
      "\n",
      "21 half_cleaned/[Dale_Carnegie]_How_to_Develop_Self-Confidence_And.txt\n",
      "\n",
      "22 half_cleaned/The_Trifecta_Secret_of_Wealth___Abundance_____Align_Your_Higher_Self___You_Shall_Arrive_nodrm.txt\n",
      "\n",
      "23 half_cleaned/Healing Your Emotional Self - Beverly Engel.txt\n",
      "\n",
      "24 half_cleaned/selfhelpbook.txt\n",
      "\n",
      "25 half_cleaned/See You at the Top - Zig Ziglar.txt\n",
      "\n",
      "26 half_cleaned/Getting More Done.txt\n",
      "\n",
      "27 half_cleaned/365 Ways to Live Happy Simple Ways to Find Joy Every Day.txt\n",
      "\n",
      "28 half_cleaned/building-self-esteem-quick-boost-method.txt\n",
      "\n",
      "29 half_cleaned/B. Alan Wallace - 2006 - The Attention Revolution - Unlocking the Power of the Focused Mind (223p).txt\n",
      "\n",
      "30 half_cleaned/Flow_-_The_Psychology_of_Optimal_Experience_-_Miha.txt\n",
      "\n",
      "31 half_cleaned/thepowerofnow.txt\n",
      "\n",
      "32 half_cleaned/50 Mindful Steps to Self-Esteem.txt\n",
      "\n",
      "58 half_cleaned/M J V Fennell - Overcoming low Self-Esteem.txt\n",
      "\n",
      "59 half_cleaned/What_to_Say_When_You_Talk_to_Your_Self.txt\n",
      "\n",
      "60 half_cleaned/Jim Donovan - Handbook To A Happier Life.txt\n"
     ]
    }
   ],
   "source": [
    "paths = [os.path.join(new_dir, name) for name in os.listdir(new_dir)]\n",
    "\n",
    "for i, path in enumerate(paths): #[i:i+1]:\n",
    "    with open(path, 'r',  encoding=\"utf-8\") as f:\n",
    "        print()\n",
    "        print(i, path)\n",
    "        lines = f.readlines()\n",
    "        paras = combine_lines(lines)\n",
    "        \n",
    "    with open(os.path.join('half_cleaned.txt'), 'a',  encoding=\"utf-8\") as f:\n",
    "        for line in paras:\n",
    "            f.write(line+'\\n')\n",
    "            f.write('\\n')\n",
    "#             print(line)\n",
    "#             print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165510\n",
      "137516\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('half_cleaned.txt'), 'r',  encoding=\"utf-8\") as f:\n",
    "    i = 0\n",
    "    paras = f.readlines()\n",
    "    new_lines = []\n",
    "    while i < len(paras):\n",
    "\n",
    "        line = paras[i]\n",
    "        \n",
    "        words = line.strip('\\n').split(' ')\n",
    "        words = [word for word in words if word != ' ' and word != '']\n",
    "\n",
    "        if len(line) > 8 and (words[-1][-1] not in ['?', '.', '?', '...', '\"']) and i < len(paras) - 2:\n",
    "            line = line.strip('\\n') + ' ' + paras[i+2]\n",
    "            i += 3\n",
    "        else:\n",
    "            i += 1\n",
    "        #i += 1\n",
    "            \n",
    "        new_lines.append(line)\n",
    "        \n",
    "    import copy\n",
    "    paras = copy.deepcopy(new_lines)\n",
    "    new_lines = []\n",
    "    print(len(paras))\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(paras):\n",
    "\n",
    "        line = paras[i]\n",
    "        \n",
    "        words = line.strip('\\n').split(' ')\n",
    "        words = [word for word in words if word != ' ' and word != '']\n",
    "\n",
    "        if len(line) > 8 and (words[-1][-1] not in ['?', '.', '?', '...', '\"']) and i < len(paras) - 2:\n",
    "            line = line.strip('\\n') + ' ' + paras[i+2]\n",
    "            i += 3\n",
    "        else:\n",
    "            i += 1\n",
    "        #i += 1\n",
    "            \n",
    "        new_lines.append(line)\n",
    "    print(len(new_lines))\n",
    "    \n",
    "with open(os.path.join('half_cleaned2.txt'), 'w',  encoding=\"utf-8\") as f:\n",
    "    for line in new_lines:\n",
    "        f.write(line)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('half_cleaned2.txt'), 'r',  encoding=\"utf-8\") as f:\n",
    "    i = 0\n",
    "    paras = f.readlines()\n",
    "    new_lines = []\n",
    "    while i < len(paras):\n",
    "\n",
    "        line = paras[i]\n",
    "        i += 1\n",
    "        words = line.strip('\\n').split(' ')\n",
    "        words = [word for word in words if word != ' ' and word != '']\n",
    "\n",
    "        if len(line) > 8 and (words[-1][-1] not in ['?', '.', '!', '...', '\"']) and i < len(paras) - 2:\n",
    "            try:\n",
    "                last_idx = max([j for j, x in enumerate(words) if x[-1] in ['.', '?', '!']])\n",
    "                words = words[:last_idx+1]\n",
    "                line = ' '.join([word for word in words])+'\\n'\n",
    "            except ValueError:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "        if len(words) < 4:\n",
    "            continue\n",
    "            \n",
    "        new_lines.append(line)\n",
    "        \n",
    "\n",
    "    \n",
    "with open(os.path.join('half_cleaned3.txt'), 'w',  encoding=\"utf-8\") as f:\n",
    "    for line in new_lines:\n",
    "        f.write(line)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['.', '?', '.', 'l']\n",
    "x = max([i for i, x in enumerate(a) if x in ['.', '?']])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
